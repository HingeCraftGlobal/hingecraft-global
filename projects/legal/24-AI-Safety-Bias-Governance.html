<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Safety, Bias & Governance Policy - HingeCraft Global, LLC</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Times New Roman', Times, serif; font-size: 12pt; line-height: 1.6; color: #000; background: #fff; max-width: 8.5in; margin: 0 auto; padding: 1in; }
        h1 { font-size: 18pt; font-weight: bold; text-align: center; margin-bottom: 24pt; text-transform: uppercase; border-bottom: 2px solid #000; padding-bottom: 12pt; }
        h2 { font-size: 14pt; font-weight: bold; margin-top: 24pt; margin-bottom: 12pt; text-transform: uppercase; }
        h3 { font-size: 12pt; font-weight: bold; margin-top: 18pt; margin-bottom: 9pt; }
        p { margin-bottom: 12pt; text-align: justify; }
        ul, ol { margin-left: 36pt; margin-bottom: 12pt; }
        li { margin-bottom: 6pt; }
        .header { text-align: center; margin-bottom: 36pt; }
        .company-name { font-size: 16pt; font-weight: bold; }
        .footer { margin-top: 48pt; padding-top: 12pt; border-top: 1px solid #000; font-size: 10pt; text-align: center; }
    </style>
</head>
<body>
    <div class="header">
        <div class="company-name">HINGECRAFT GLOBAL, LLC</div>
        <h1>AI SAFETY, BIAS &<br>GOVERNANCE POLICY</h1>
        <p>Effective Date: December 6, 2025<br>State of South Carolina</p>
    </div>

    <h2>1. PURPOSE AND SCOPE</h2>
    
    <p><strong>1.1 Purpose.</strong> This AI Safety, Bias & Governance Policy ("Policy") establishes HingeCraft Global, LLC's ("HingeCraft" or "Company") framework for the responsible development, deployment, and use of artificial intelligence (AI) and machine learning (ML) systems.</p>
    
    <p><strong>1.2 Scope.</strong> This Policy applies to: (a) All AI and ML systems developed or deployed by HingeCraft; (b) Third-party AI systems integrated into HingeCraft products or services; (c) All employees, contractors, and partners involved in AI development or deployment.</p>
    
    <p><strong>1.3 Commitment.</strong> HingeCraft is committed to: (a) Developing AI that is safe, fair, and beneficial; (b) Preventing and mitigating AI-related harms; (c) Maintaining human oversight and control; (d) Transparency about AI capabilities and limitations; (e) Continuous improvement of AI governance.</p>

    <h2>2. PRINCIPLES</h2>
    
    <h3>2.1 Safety</h3>
    <p>AI systems must: (a) Be designed with safety as a primary consideration; (b) Include appropriate safeguards and fail-safes; (c) Be tested rigorously before deployment; (d) Be monitored continuously for safety issues; (e) Allow for human intervention when needed.</p>
    
    <h3>2.2 Fairness</h3>
    <p>AI systems must: (a) Treat all individuals and groups fairly; (b) Avoid discrimination based on protected characteristics; (c) Be tested for bias before and after deployment; (d) Include mechanisms for bias detection and correction.</p>
    
    <h3>2.3 Transparency</h3>
    <p>AI systems must: (a) Have documented purposes and capabilities; (b) Provide explanations for decisions when feasible; (c) Disclose AI involvement to affected individuals; (d) Maintain audit trails for accountability.</p>
    
    <h3>2.4 Privacy</h3>
    <p>AI systems must: (a) Comply with privacy laws and policies; (b) Minimize data collection and retention; (c) Protect personal information used for training; (d) Respect user consent preferences.</p>
    
    <h3>2.5 Accountability</h3>
    <p>AI systems must: (a) Have clear ownership and responsibility; (b) Include mechanisms for redress; (c) Be subject to regular review and audit; (d) Allow for human oversight and override.</p>

    <h2>3. GOVERNANCE STRUCTURE</h2>
    
    <h3>3.1 AI Ethics Committee</h3>
    <p>An AI Ethics Committee oversees AI governance: (a) Reviews high-risk AI applications; (b) Develops and updates AI policies; (c) Investigates AI-related concerns; (d) Reports to executive management.</p>
    
    <h3>3.2 AI Product Owners</h3>
    <p>Each AI system has a designated owner responsible for: (a) Compliance with this Policy; (b) Risk assessment and mitigation; (c) Monitoring and maintenance; (d) Incident response.</p>
    
    <h3>3.3 Data Science Team</h3>
    <p>The Data Science Team is responsible for: (a) Technical implementation of safeguards; (b) Bias testing and mitigation; (c) Model documentation; (d) Technical review of AI systems.</p>

    <h2>4. RISK ASSESSMENT</h2>
    
    <h3>4.1 Risk Categories</h3>
    <p>AI applications are categorized by risk level:</p>
    <ul>
        <li><strong>High Risk:</strong> Systems affecting health, safety, legal rights, or significant financial decisions;</li>
        <li><strong>Medium Risk:</strong> Systems with moderate impact on individuals;</li>
        <li><strong>Low Risk:</strong> Systems with minimal individual impact (e.g., product recommendations).</li>
    </ul>
    
    <h3>4.2 Assessment Process</h3>
    <p>Before deployment, AI systems undergo: (a) Purpose and scope documentation; (b) Data quality assessment; (c) Bias evaluation; (d) Safety and security review; (e) Privacy impact assessment; (f) Ethics review (for high-risk systems).</p>

    <h2>5. BIAS PREVENTION AND MITIGATION</h2>
    
    <h3>5.1 Data Quality</h3>
    <p>Training data must: (a) Be representative of intended use populations; (b) Be reviewed for historical biases; (c) Include diverse perspectives; (d) Be documented and auditable.</p>
    
    <h3>5.2 Testing</h3>
    <p>AI systems are tested for bias: (a) Before initial deployment; (b) Regularly after deployment; (c) After significant updates; (d) When issues are reported.</p>
    
    <h3>5.3 Mitigation</h3>
    <p>When bias is identified: (a) Assess severity and impact; (b) Implement technical corrections; (c) Adjust training data if needed; (d) Document and report findings; (e) Monitor for recurrence.</p>

    <h2>6. SAFETY REQUIREMENTS</h2>
    
    <h3>6.1 Design for Safety</h3>
    <p>AI systems must: (a) Have defined operating boundaries; (b) Include input validation; (c) Handle edge cases gracefully; (d) Fail safely when errors occur; (e) Allow human override.</p>
    
    <h3>6.2 Testing</h3>
    <p>Safety testing includes: (a) Functional testing; (b) Stress testing; (c) Adversarial testing; (d) Edge case testing; (e) Red team exercises (for high-risk systems).</p>
    
    <h3>6.3 Monitoring</h3>
    <p>Deployed systems are monitored for: (a) Performance degradation; (b) Unexpected outputs; (c) Safety incidents; (d) User feedback; (e) Model drift.</p>

    <h2>7. TRANSPARENCY AND EXPLAINABILITY</h2>
    
    <h3>7.1 Disclosure</h3>
    <p>We disclose: (a) When AI is being used; (b) The purpose of AI use; (c) How AI decisions are made (where feasible); (d) Options for human review.</p>
    
    <h3>7.2 Documentation</h3>
    <p>AI systems must have: (a) Model cards describing capabilities and limitations; (b) Data documentation; (c) Decision documentation; (d) Audit logs.</p>
    
    <h3>7.3 Explainability</h3>
    <p>For significant decisions: (a) Provide meaningful explanations when feasible; (b) Identify key factors in decisions; (c) Offer human review options.</p>

    <h2>8. HUMAN OVERSIGHT</h2>
    
    <p><strong>8.1 Human-in-the-Loop.</strong> High-risk decisions require human review before action.</p>
    
    <p><strong>8.2 Human-on-the-Loop.</strong> Medium-risk systems require human monitoring with ability to intervene.</p>
    
    <p><strong>8.3 Override Capability.</strong> All AI systems must allow human override of automated decisions.</p>

    <h2>9. INCIDENT RESPONSE</h2>
    
    <p><strong>9.1 Reporting.</strong> AI-related incidents must be reported to the AI Ethics Committee immediately.</p>
    
    <p><strong>9.2 Investigation.</strong> Incidents are investigated to determine: (a) Root cause; (b) Impact; (c) Corrective actions; (d) Preventive measures.</p>
    
    <p><strong>9.3 Remediation.</strong> Affected individuals receive: (a) Notification; (b) Explanation; (c) Remediation of any harm; (d) Information about changes made.</p>

    <h2>10. THIRD-PARTY AI</h2>
    
    <p>Before using third-party AI: (a) Conduct due diligence on the provider; (b) Review the AI for compliance with this Policy; (c) Obtain appropriate documentation; (d) Establish contractual requirements; (e) Monitor performance.</p>

    <h2>11. TRAINING</h2>
    
    <p>Personnel involved in AI development and deployment receive training on: (a) This Policy; (b) AI ethics principles; (c) Bias recognition and mitigation; (d) Safety requirements; (e) Privacy considerations.</p>

    <h2>12. REVIEW AND UPDATE</h2>
    
    <p>This Policy is reviewed annually and updated to reflect: (a) Changes in technology; (b) New regulations and standards; (c) Lessons learned; (d) Best practices.</p>

    <h2>13. CONTACT</h2>
    
    <p>For questions or to report concerns:</p>
    <p>HingeCraft Global, LLC<br>
    AI Ethics Committee<br>
    123 Innovation Drive, Suite 100<br>
    Charleston, South Carolina 29401<br>
    Email: ai-ethics@hingecraft.com<br>
    Phone: (843) 555-0100</p>

    <div class="footer">
        <p>HingeCraft Global, LLC | 123 Innovation Drive, Suite 100, Charleston, SC 29401</p>
        <p>AI Ethics: ai-ethics@hingecraft.com | Phone: (843) 555-0100</p>
        <p>Â© 2025 HingeCraft Global, LLC. All Rights Reserved.</p>
    </div>
</body>
</html>



